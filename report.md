# Отчет

В рамках лабораторной работы были реализованы скрипты Map и Reduce, а также
управляющий ими скрипт MapReduce. Описание их интерфейса доступно в файле
README. Входные данные для проверки их работы можно сгенерировать 
Python-скриптом `generate.py` (чуть подробнее о нем можно прочитать ниже).

На всех этапах используются обычные файлы (не бинарные). Это сильно упрощает
реализацию (в частности, не нужно следить за длиной строк). Большого выигрыша
по объему памяти от перехода на бинарные файлы в данной задаче мы не получим,
так как почти все данные - это строки. В перспективе, тем не менее, переход на
бинарный ввод / вывод вполне возможен (для этого достаточно лишь реализовать
логику его парсинга).

При реализации оказалось, что многая функциональность (работа со временными
файлами, буферизация ввода и вывода) необходима в различных частях программы.
В связи с этим было принято решение вынести ее в отдельные классы, которые
могут быть использованы любыми скриптами.

В этом отчете сначала будут рассмотрены реализации этих вспомогательных
классов, затем реализации непосредственно Map, Reduce и MapReduce.

# Вспомогательные классы

## Работа со временными файлами

За работу со временными файлами отвечает класс `TempFilesManager`. Основная его
функциональность:

* Разбиение входного файла по блокам разными способами и копирование 
соответствующих данных во временные файлы. Разбиение на блоки фиксированной
длины используется в скрипте Map и в алгоритме внешней сортировки, разбиение на
блоки, соответствующие одному ключу, - в скрипте Reduce.

* Запуск какого-либо скрипта на каждом из временных файлов. Используется в 
скриптах Map и Reduce, реализован на базе механизмов `boost::process`. В
перспективе реализация может быть улучшена путем регулирования количества 
одновременно работающих процессов.

* Сортировка каждого из временных файлов (лексикографически по строкам).
Используется в алгоритме внешней сортировки, предполагает, что объем данных в
одном файле помещается в оперативную память. Более подробно описана ниже.

* Слияние временных файлов в один. Используется на финальных стадиях Map и 
Reduce.

* Слияние отсортированных временных файлов в один. Основная часть алгоритма
внешней сортировки. Подробно описывать его здесь я не буду, основные принципы
совершенно обычны (при слиянии используется куча, для оптимизации
быстродействия файловый ввод и вывод буферизуются).

Помимо описанной функциональности, данный класс, очевидно, содержит все
необходимое для создания и удаления временных файлов. Он отвечает за выбор
случайного имени для файла, он удаляет все созданные файлы в деструкторе, и
так далее.

Как можно было понять, бо́льшая часть алгоритма внешней сортировки также неявно
реализована именно в этом классе.

## Буферизация ввода и вывода

Для буферизации ввода и вывода на всех этапах работы всех скриптов используются
собственные реализации классов `BufferedReader` и `BufferedWriter`.

Логика достаточно проста. `BufferedReader` считывает сразу блок последующих
строк во внутренний буфер (`std::deque`), отдавая затем их в порядке FIFO.
`BufferedWriter` имеет буфер в виде `std::ostringstream` и сбрасывает его
(записывает данные в реальный файл), когда размер буфера превышает некую
константу. Для удобства вывода объектов разных типов в классе перегружен
оператор `<<`.

## Управление потоками

В алгоритме внешней сортировки есть этап, когда нужно независимо друг от друга
отсортировать множество относительно небольших файлов. Это логично делать в
нескольких потоках. Запускать сразу огромное количество потоков или создавать
на каждый файл новый поток достаточно затратно, и избежать этих расходов можно
с помощью использования ThreadPool.

Реализация ThreadPool в проекте основана на соответствующей реализации в рамках
проекта Google's Operations Research. Она была немного исправлена (в исходной
реализации были возможны deadlocks, на что обращала внимание даже утилита
valgrind) и упрощена (убран контроль за количеством задач, так как в нашем
случае они точно не будут исчисляться миллиардами).

Что-то похожее в перспективе можно будет написать для управления
процессами, так как все недостатки запуска тысяч потоков одновременно
характерны и для запуска тысяч процессов одновременно.

## Другие задачи

Помимо описанных выше, были реализованы и другие вспомогательные функции,
объединяющие в одном месте часто используемую логику. Например, для парсинга
идентификаторов пользователей явно используется соответствующая функция, а не
напрямую какая-нибудь функция `std::strtoull`, так как в перспективе формат
хранения идентификаторов вполне может поменяться.

# Map

На стадии Map входные данные конвертируются из одного формата в другой, более
удобный для дальнейшей сортировки и стадии Reduce. Конкретные форматы указаны
в README, а также в комментариях в файле с исходным кодом.

Как указано в README, на стадии Map входной файл сначала делится на более
мелкие, для которых затем и запускается конвертация. После этого они сливаются
обратно в один файл.

Следует отметить, что после этого этапа нет никаких гарантий касательно порядка
строк в выходном файле. Гарантируется лишь соблюдение формата. Строки,
соответствующие одному и тому же пользователю, и даже одной и той же паре
"пользователь-сайт" могут быть разбросаны по всему файлу, и это нормально.

# Sort

Сортировка запускается автоматически перед операцией Reduce, по ее окончании
соответствующее сообщение выводится в `std::clog`. Для сортировки входной файл
делится на блоки, которые затем сортируются обычным in-memory алгоритмом.
После этого блоки снова объединяются в один файл с помощью структуры данных
куча.

Сортировка отдельных файлов запускается в многопоточном режиме, для этого
используется класс ThreadPool. Количество создаваемых потоков специально в
несколько раз превышает количество ядер процессора. Это нужно для оптимизации
взаимной работы процессора и диска, чтобы не возникало ситуации, когда все ядра
процессора работают над сортировкой, а диск простаивает, вместо того, чтобы
подгружать данные из следующего файла.

Следует отметить, что строки в файлах сортируются лексикографически. Этого
достаточно для гарантии того, что все строки, соответствующие одному
идентификатору пользователя, окажутся в итоговом файле рядом (а большего нам
и не надо). Такая гарантия очевидно обеспечивается, так как любая строка
начинается с идентификатора. Этот способ сортировки не гарантирует, что в
итоге идентификаторы пользователей будут идти в порядке возрастания (так как,
например, "1000" < "87"). Но такого от нас и не требовалось. При желании это,
конечно, можно реализовать, чуть-чуть усложнив логику парсинга строк при
сортировке.

# Reduce

После сортировки один большой файл разбивается на множество мелких,
соответствующих одному идентификатору. Это сделать очень легко, так как строки
с одним и тем же идентификатором после сортировки находятся рядом друг с
другом, в блоках.

Каждый файл обрабатывается в предположении, что данные в нем поместятся в
оперативную память. Для пользователя формируется map вида "сайт -> посещения".
Далее для каждого сайта подсчитывается значение среднего времени нахождения
на сайте, минимальное и максимальное время, и эта информация выводится в
итоговый файл.

Если вдруг в одном файле будут находиться строки, соответствующие разным
идентификаторам, поведение программы будет не определено  (но она выведет в
`stderr` соответствующее сообщение).

Формат вывода был немного изменен по сравнению с требуемым в условии для
более удобного восприятия человеком. При необходимости он чрезвычайно легко
редактируется. В текущей реализации анализ поведения пользователя также легко
дополнить (например, считать еще и количество посещений, и так далее).

# Тестирование

Для тестирования работы программы был написан скрипт на Python, который может
сгенерировать помещающийся в оперативную память объем данных и вывести его в
нужном формате в файл (который затем надо передать Map и Reduce). Параметры
генератора настраиваются прямо в коде скрипта (там явно заданы соответствующие
константы).

Для проверки ошибок можно сравнивать вывод MapReduce с явным выводом того, что
сгенерировал Python (после генерации файла скрипт уходит в режим ожидания, по
вводу конкретного идентификатора пользователя он выводит на экран
соответствующие ему данные, которые были сгенерированы и выведены во входной
файл).
